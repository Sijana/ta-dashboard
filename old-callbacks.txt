# Callback for handling file upload
    # @app.callback(
    #     [Output('upload-validation', 'children'),
    #     Output('dashboard-content', 'style'),
    #     Output('university-dropdown', 'options'),
    #     Output('department-dropdown', 'options'),
    #     Output('job-title-dropdown', 'options'),
    #     Output('university-dropdown', 'value'),
    #     Output('department-dropdown', 'value'),
    #     Output('run-demo-state', 'children')],
    #     [Input('upload-data', 'contents'),
    #     Input('run-demo-btn', 'n_clicks')],
    #     [State('upload-data', 'filename')],
    #     prevent_initial_call=True
    # )
    # def process_data(contents, demo_clicks, filename):
    #     ctx = dash.callback_context

    #     # Determine which button triggered the callback
    #     if not ctx.triggered:
    #         return '', {'display': 'none'}, [], [], None, None

    #     trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]
    #     # Initialize run-demo-state as None (for the case no button was clicked)
    #     run_demo_state = None

    #     # If "Run Demo" was clicked
    #     if trigger_id == 'run-demo-btn':
    #         demo_csv_path = 'demo_data.csv'

    #         try:
    #             df = pd.read_csv(demo_csv_path)
    #             run_demo_state = 'demo'
    #         except Exception as e:
    #             return f"Error loading demo data: {str(e)}", {'display': 'none'}, [], [], None, None

    #     # If a file was uploaded
    #     elif trigger_id == 'upload-data':
    #         if not contents:
    #             return '', {'display': 'none'}, [], [], None, None

    #         try:
    #             content_type, content_string = contents.split(',')
    #             decoded = base64.b64decode(content_string)
    #             df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))
    #         except Exception as e:
    #             return f"Error processing file 1: {str(e)}", {'display': 'none'}, [], [], None, None

    #     # Validate data
    #     required_columns = [
    #         'employee_id', 'university', 'graduation_grade',
    #         'department', 'job_title', 'start_date',
    #         'performance_score', 'years_of_experience',
    #         'age', 'salary'
    #     ]
    #     missing_columns = [col for col in required_columns if col not in df.columns]
    #     if missing_columns:
    #         return f"Missing columns: {', '.join(missing_columns)}", {'display': 'none'}, [], [], None, None

    #     # Prepare dropdown options
    #     university_options = [{'label': uni, 'value': uni} for uni in sorted(df['university'].unique())]
    #     department_options = [{'label': dept, 'value': dept} for dept in sorted(df['department'].unique())]
    #     job_title_options = [{'label': title, 'value': title} for title in sorted(df['job_title'].unique())]

    #     return (
    #         f"Successfully processed data from {trigger_id.replace('-', ' ')}.",
    #         {'display': 'block'},  # Show dashboard
    #         university_options,
    #         department_options,
    #         job_title_options,
    #         None,  # Default for university
    #         None, # Default for department
    #         run_demo_state
    #     )

    @app.callback(
        [Output('insights-container', 'children'),
        Output('performance-by-university', 'figure'),
        Output('salary-distribution', 'figure'),
        Output('experience-salary-scatter', 'figure'), # Added this and next two lines
        Output('salary-department-boxplot', 'figure'),
        Output('performance-heatmap', 'figure'),
        Output('data-table', 'columns'),
        Output('data-table', 'data')],
        [Input('run-demo-state', 'children'),
        Input('upload-data', 'contents'),
        Input('run-demo-btn', 'n_clicks'),
        Input('university-dropdown', 'value'),
        Input('department-dropdown', 'value'),
        Input('job-title-dropdown', 'value')],
        [State('upload-data', 'filename')],
        prevent_initial_call=True
    )
    def update_dashboard(run_demo_state, contents, demo_clicks, selected_university, selected_department, selected_job_title, filename):
        if run_demo_state == 'demo':
            # Load demo data
            demo_csv_path = 'demo_data.csv'
            try:
                df = pd.read_csv(demo_csv_path)
            except Exception as e:
                return f"Error loading demo data: {str(e)}", {}, {}, [], []

        elif contents: # If contents are provided (i.e., a file was uploaded)
            try:
                content_type, content_string = contents.split(',')
                decoded = base64.b64decode(content_string)
                df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))
            except Exception as e:
                return f"Error processing file 2: {str(e)}", {}, {}, [], []

        else:
            return "No data available 1", {}, {}, [], []

        # Apply filters
        print(df.head())
        filtered_df = df.copy()
        print("filtered df:")
        #print(filtered_df.head())

        if selected_university:
            filtered_df = filtered_df[filtered_df['university'] == selected_university]

        if selected_department:
            filtered_df = filtered_df[filtered_df['department'] == selected_department]

        if selected_job_title:
            filtered_df = filtered_df[filtered_df['job_title'] == selected_job_title]

        # Handle empty filtered data
        if filtered_df.empty:
            return (
                "No data available for the selected filters.",
                go.Figure(),
                go.Figure(),
                [],
                []
            )
        # 1. Scatter Plot: Years of Experience vs Salary
        experience_salary_fig = px.scatter(
            filtered_df,
            x='years_of_experience',
            y='salary',
            color='department',
            title='Salary vs Years of Experience',
            labels={'years_of_experience': 'Years of Experience', 'salary': 'Salary ($)'},
            hover_data=['employee_id', 'job_title']
        )
        experience_salary_fig.update_layout(
            xaxis_title='Years of Experience',
            yaxis_title='Salary ($)'
        )

        # 2. Box Plot: Salary Distribution by Department
        salary_department_fig = go.Figure()
        for department in filtered_df['department'].unique():
            dept_data = filtered_df[filtered_df['department'] == department]['salary']
            salary_department_fig.add_trace(
                go.Box(
                    y=dept_data,
                    name=department,
                    boxmean=True  # Add mean marker
                )
            )
        salary_department_fig.update_layout(
            title='Salary Distribution by Department',
            yaxis_title='Salary ($)',
            xaxis_title='Department'
        )

        # 3. Heatmap: Performance Scores Correlation
        # Select numerical columns for correlation
        numerical_columns = ['graduation_grade', 'performance_score',
                            'years_of_experience', 'age', 'salary']
        correlation_matrix = filtered_df[numerical_columns].corr()

        performance_heatmap = go.Figure(data=go.Heatmap(
            z=correlation_matrix.values,
            x=correlation_matrix.columns,
            y=correlation_matrix.columns,
            colorscale='RdBu_r',
            zmin=-1,
            zmax=1
        ))
        performance_heatmap.update_layout(
            title='Correlation Heatmap of Performance-Related Attributes',
            xaxis_title='Attributes',
            yaxis_title='Attributes'
        )
        # Insights
        insights = {
            'total_employees': len(filtered_df),
            'average_performance': filtered_df['performance_score'].mean(),
            'average_salary': filtered_df['salary'].mean()
        }

        insights_cards = [
            html.Div([
                html.H4('Total Employees'),
                html.P(f"{insights['total_employees']}")
            ]),
            html.Div([
                html.H4('Avg Performance'),
                html.P(f"{insights['average_performance']:.2f}")
            ]),
            html.Div([
                html.H4('Avg Salary'),
                html.P(f"${insights['average_salary']:,.2f}")
            ])
        ]

        # Visualizations
        performance_fig = px.bar(
            filtered_df.groupby('university')['performance_score'].mean().reset_index(),
            x='university', y='performance_score', title='Performance by University'
        )

        salary_fig = px.histogram(
            filtered_df, x='salary', title='Salary Distribution'
        )

        # Data Table
        columns = [{"name": i, "id": i} for i in filtered_df.columns]

        return (
            insights_cards,
            performance_fig,
            salary_fig,
            experience_salary_fig,
            salary_department_fig,
            performance_heatmap,
            columns,
            filtered_df.to_dict('records')
        )
    
    # Callback for ML model insights
    @app.callback(
        [Output('salary-prediction-model-insights', 'children'),
         Output('feature-importance-chart', 'figure'),
         Output('employee-clustering-chart', 'figure')],
        [Input('run-demo-state', 'children'),
         Input('upload-data', 'contents')],
        prevent_initial_call=True
    )
    def update_ml_insights(run_demo_state, contents):
        # Load data similar to previous callbacks
        if run_demo_state == 'demo':
            df = pd.read_csv('demo_data.csv')
        elif contents:
            content_type, content_string = contents.split(',')
            decoded = base64.b64decode(content_string)
            df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))
        else:
            return "No data available", {}, {}
        
        # Generate ML insights
        ml_insights = create_ml_insights(df)
        
        # Salary Prediction Insights
        salary_insights = [
            html.P(f"Model Training Accuracy: {ml_insights['train_score']:.2%}"),
            html.P(f"Model Testing Accuracy: {ml_insights['test_score']:.2%}")
        ]
        
        # Feature Importance Visualization
        feature_importance_fig = px.bar(
            ml_insights['feature_importance'], 
            x='Feature', 
            y='Importance', 
            title='Feature Importance for Salary Prediction'
        )
        
        # Clustering Visualization
        clustering_fig = px.scatter(
            ml_insights['clustering_df'], 
            x='PCA1', 
            y='PCA2', 
            color='Cluster', 
            hover_data=['Salary', 'Department'],
            title='Employee Clustering Visualization'
        )
        
        return salary_insights, feature_importance_fig, clustering_fig


        def create_ml_insights(df):
    """
    Generate machine learning insights from the dataframe
    
    Args:
        df (pandas.DataFrame): Input dataframe
    
    Returns:
        dict: Machine learning insights
    """
    # Prepare features for ML
    features = ['graduation_grade', 'years_of_experience', 'age', 'performance_score']
    X = df[features]
    y = df['salary']

    # Standardize features
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # 1. Salary Prediction Model
    # Split data (simple train/test split)
    from sklearn.model_selection import train_test_split
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
    
    # Train Linear Regression Model
    salary_predictor = LinearRegression()
    salary_predictor.fit(X_train, y_train)
    
    # Model Performance
    train_score = salary_predictor.score(X_train, y_train)
    test_score = salary_predictor.score(X_test, y_test)

    # 2. Clustering
    # Use K-Means clustering
    kmeans = KMeans(n_clusters=3, random_state=42)
    cluster_labels = kmeans.fit_predict(X_scaled)

    # Dimensionality Reduction for Visualization
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X_scaled)

    # Prepare clustering visualization data
    clustering_df = pd.DataFrame({
        'PCA1': X_pca[:, 0],
        'PCA2': X_pca[:, 1],
        'Cluster': cluster_labels,
        'Salary': y,
        'Department': df['department']
    })

    # 3. Feature Importance for Salary Prediction
    feature_importance = pd.DataFrame({
        'Feature': features,
        'Importance': np.abs(salary_predictor.coef_)
    }).sort_values('Importance', ascending=False)

    return {
        'salary_predictor': salary_predictor,
        'scaler': scaler,
        'train_score': train_score,
        'test_score': test_score,
        'clustering_df': clustering_df,
        'feature_importance': feature_importance
    }